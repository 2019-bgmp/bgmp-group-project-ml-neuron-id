{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: train_spot.ipynb\n",
    "Authors: Jared Galloway\n",
    "Date: 1/15/2020\n",
    "\n",
    "This Jupyter Notebook will exemplify the workflow for simulating \n",
    "a dataset of spots with thier respective annotations - \n",
    "then train a neural network to parse out dots from background noise.\n",
    "\n",
    "Finally, we will import an empirical flurescent microscopy image and\n",
    "Predict on The image before computing the F1 score as a metric of accuracy.\n",
    "\n",
    "This Workflow is proof of concepy that spots can be simulted \n",
    "easily and accuratly enough to train a convolutional nueral network\n",
    "on the task of spot detection for a range of empitical scenerios.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# External Dependencies\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "# Internal Dependencies \n",
    "sys.path.insert(0,\"../\")\n",
    "import scripts.networks as nets\n",
    "import scripts.helpers as helpers\n",
    "import scripts.dot_simulator as dot_simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dot_simulator.single_layers_simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory to place output files and location of test files\n",
    "EXP_DIR = \"../scripts/L1-D02-z_490_448_64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Some parameters\n",
    "params = {\"num_samples\":1500,\n",
    "            \"width\":64,\n",
    "            \"height\":64,\n",
    "            \"num_dots_n\": 0,\n",
    "            \"num_dots_p\": 0.85,\n",
    "            \"radii_n\":4,\n",
    "            \"radii_p\":0.65,\n",
    "            \"spot_noise\":0.2,\n",
    "            \"point_noise\":0.2,\n",
    "            \"background_noise\":0.15}\n",
    "\n",
    "# Simulate!\n",
    "start = time.time()\n",
    "x, y = dot_simulator.single_layers_simulator(**params)\n",
    "finish = time.time()\n",
    "print(f\"Simulations took {round(finish - start,2)} seconds\")\n",
    "\n",
    "print(f\"simulated data examples has shape: {x.shape}\")\n",
    "print(f\"simulated data set targets has shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what (roughly) our distribution of dots, and radii will be ...\n",
    "# dots = np.random.binomial(n = params[\"num_dots_n\"], p = params[\"num_dots_p\"], size = params[\"num_samples\"])\n",
    "dots = np.random.binomial(n = params[\"num_dots_n\"], p = params[\"num_dots_p\"], size = 10000)\n",
    "radii = np.random.binomial(n = params[\"radii_n\"], p = params[\"radii_p\"], size = sum(dots))\n",
    "fig, ax = plt.subplots(1,2, figsize=(14, 7))\n",
    "ax[0].hist(dots)\n",
    "ax[0].set_title(\"Exp Number of Dots across Images\")\n",
    "ax[1].hist(radii)\n",
    "ax[1].set_title(\"Exp Size of radii across Spots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INDEX = 0\n",
    "fig, ax = plt.subplots(1,2,figsize=(14, 11))\n",
    "ax[0].imshow(np.squeeze(x[IMAGE_INDEX]))\n",
    "ax[1].imshow(np.squeeze(y[IMAGE_INDEX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut data set up into train, validation, and testing.\n",
    "\n",
    "percent_test = 0.1\n",
    "percent_validation = 0.2\n",
    "\n",
    "test_split = int(x.shape[0] * percent_test) \n",
    "vali_split = int(x.shape[0] * percent_validation)\n",
    "\n",
    "test_x = x[:test_split,:,:,:]\n",
    "vali_x = x[test_split:vali_split,:,:,:]\n",
    "train_x = x[vali_split:,:,:,:]\n",
    "\n",
    "test_y = y[:test_split,:,:,:]\n",
    "vali_y = y[test_split:vali_split,:,:,:]\n",
    "train_y = y[vali_split:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a model!\n",
    "model = nets.deeper_direct_CNN(x,y)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with our simulated data\n",
    "model.fit(train_x, train_y, \n",
    "        validation_data = (vali_x, vali_y),\n",
    "        epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an empirical image for testing!\n",
    "test_emp_image = np.load(f\"{EXP_DIR}/{EXP_DIR[11:]}_image_scaled.out\", allow_pickle = True)\n",
    "test_emp_image = np.reshape(test_emp_image,(1,64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the empirical image\n",
    "# TODO : Take a look at the entire Image.\n",
    "fig, ax = plt.subplots(1, figsize=(7, 6.5))\n",
    "ax.imshow(np.squeeze(test_emp_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, lets use our model trained on simulations to predict on the real thing!\n",
    "pred_emp = model.predict(test_emp_image)\n",
    "pred_sim = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look!\n",
    "fig, ax = plt.subplots(1,2, figsize=(14, 13))\n",
    "ax[0].imshow(np.squeeze(test_emp_image))\n",
    "ax[1].imshow(np.squeeze(pred_emp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
